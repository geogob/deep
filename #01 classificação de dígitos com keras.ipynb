{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_treino, y_treino),(x_teste, y_teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_convertido = np_utils.to_categorical(y_treino)\n",
    "y_teste_convertido = np_utils.to_categorical(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino_convertido #verificando se converteu corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feef9987f10>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_treino[0], cmap='gray') #imprimindo uma das amostras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reshape: Colocando as imagens (amostras) no formato de única linha</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_remodelado = x_treino.reshape((60000,784))\n",
    "x_teste_remodelado = x_teste.reshape((10000,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treino_remodelado.shape #testando se deu certo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Normalizando os dados (entre 0 e 1):</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_normalizado = x_teste_remodelado.astype('float32')/255\n",
    "x_treino_normalizado = x_treino_remodelado.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste_normalizado #verificando se due certo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Criando a minha rede...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(30, input_dim=784, kernel_initializer='normal', activation='relu')) #entrada e primeira camada\n",
    "modelo.add(Dense(30, kernel_initializer='normal', activation='relu')) #segunda camada\n",
    "modelo.add(Dense(10, kernel_initializer='normal', activation='softmax')) #saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 2.2899 - acc: 0.2050 - val_loss: 2.2651 - val_acc: 0.2542\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1130 - acc: 0.3122 - val_loss: 1.7799 - val_acc: 0.4672\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2984 - acc: 0.6165 - val_loss: 0.8921 - val_acc: 0.7368\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7356 - acc: 0.7789 - val_loss: 0.6093 - val_acc: 0.8128\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5648 - acc: 0.8335 - val_loss: 0.5042 - val_acc: 0.8526\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4850 - acc: 0.8594 - val_loss: 0.4463 - val_acc: 0.8684\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4362 - acc: 0.8743 - val_loss: 0.4077 - val_acc: 0.8830\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4040 - acc: 0.8840 - val_loss: 0.3816 - val_acc: 0.8886\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3822 - acc: 0.8902 - val_loss: 0.3621 - val_acc: 0.8947\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3653 - acc: 0.8954 - val_loss: 0.3486 - val_acc: 0.8982\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3518 - acc: 0.8991 - val_loss: 0.3369 - val_acc: 0.9013\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3394 - acc: 0.9030 - val_loss: 0.3258 - val_acc: 0.9044\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3285 - acc: 0.9060 - val_loss: 0.3156 - val_acc: 0.9077\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3180 - acc: 0.9083 - val_loss: 0.3059 - val_acc: 0.9097\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3080 - acc: 0.9111 - val_loss: 0.2983 - val_acc: 0.9119\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2983 - acc: 0.9140 - val_loss: 0.2881 - val_acc: 0.9160\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2889 - acc: 0.9176 - val_loss: 0.2796 - val_acc: 0.9178\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2799 - acc: 0.9204 - val_loss: 0.2722 - val_acc: 0.9206\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2715 - acc: 0.9225 - val_loss: 0.2648 - val_acc: 0.9242\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2633 - acc: 0.9243 - val_loss: 0.2556 - val_acc: 0.9249\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2553 - acc: 0.9271 - val_loss: 0.2506 - val_acc: 0.9274\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2480 - acc: 0.9283 - val_loss: 0.2415 - val_acc: 0.9309\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2409 - acc: 0.9306 - val_loss: 0.2345 - val_acc: 0.9330\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2343 - acc: 0.9324 - val_loss: 0.2285 - val_acc: 0.9351\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2280 - acc: 0.9341 - val_loss: 0.2242 - val_acc: 0.9370\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2222 - acc: 0.9359 - val_loss: 0.2178 - val_acc: 0.9371\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2168 - acc: 0.9377 - val_loss: 0.2128 - val_acc: 0.9388\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2116 - acc: 0.9393 - val_loss: 0.2101 - val_acc: 0.9408\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2066 - acc: 0.9407 - val_loss: 0.2052 - val_acc: 0.9408\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2023 - acc: 0.9413 - val_loss: 0.1999 - val_acc: 0.9425\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1982 - acc: 0.9428 - val_loss: 0.1961 - val_acc: 0.9440\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1940 - acc: 0.9440 - val_loss: 0.1930 - val_acc: 0.9454\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1904 - acc: 0.9451 - val_loss: 0.1893 - val_acc: 0.9456\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1868 - acc: 0.9456 - val_loss: 0.1869 - val_acc: 0.9475\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1836 - acc: 0.9468 - val_loss: 0.1838 - val_acc: 0.9470\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1804 - acc: 0.9476 - val_loss: 0.1806 - val_acc: 0.9487\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1771 - acc: 0.9488 - val_loss: 0.1796 - val_acc: 0.9481\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1747 - acc: 0.9491 - val_loss: 0.1765 - val_acc: 0.9496\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1717 - acc: 0.9499 - val_loss: 0.1761 - val_acc: 0.9497\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1689 - acc: 0.9506 - val_loss: 0.1733 - val_acc: 0.9499\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1665 - acc: 0.9515 - val_loss: 0.1706 - val_acc: 0.9500\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1639 - acc: 0.9524 - val_loss: 0.1706 - val_acc: 0.9511\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1617 - acc: 0.9525 - val_loss: 0.1671 - val_acc: 0.9518\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1591 - acc: 0.9535 - val_loss: 0.1667 - val_acc: 0.9509\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1569 - acc: 0.9543 - val_loss: 0.1633 - val_acc: 0.9520\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1546 - acc: 0.9549 - val_loss: 0.1624 - val_acc: 0.9528\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1526 - acc: 0.9556 - val_loss: 0.1608 - val_acc: 0.9524\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1503 - acc: 0.9563 - val_loss: 0.1610 - val_acc: 0.9529\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1485 - acc: 0.9566 - val_loss: 0.1567 - val_acc: 0.9547\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1464 - acc: 0.9577 - val_loss: 0.1563 - val_acc: 0.9543\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1446 - acc: 0.9580 - val_loss: 0.1556 - val_acc: 0.9545\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1427 - acc: 0.9587 - val_loss: 0.1552 - val_acc: 0.9539\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1408 - acc: 0.9595 - val_loss: 0.1518 - val_acc: 0.9549\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1391 - acc: 0.9597 - val_loss: 0.1541 - val_acc: 0.9551\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1374 - acc: 0.9602 - val_loss: 0.1498 - val_acc: 0.9560\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1357 - acc: 0.9609 - val_loss: 0.1490 - val_acc: 0.9556\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1339 - acc: 0.9613 - val_loss: 0.1493 - val_acc: 0.9555\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1324 - acc: 0.9614 - val_loss: 0.1484 - val_acc: 0.9565\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1307 - acc: 0.9621 - val_loss: 0.1448 - val_acc: 0.9574\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1293 - acc: 0.9626 - val_loss: 0.1447 - val_acc: 0.9575\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1276 - acc: 0.9629 - val_loss: 0.1474 - val_acc: 0.9565\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1264 - acc: 0.9634 - val_loss: 0.1421 - val_acc: 0.9580\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1246 - acc: 0.9641 - val_loss: 0.1431 - val_acc: 0.9578\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1230 - acc: 0.9646 - val_loss: 0.1413 - val_acc: 0.9577\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1217 - acc: 0.9648 - val_loss: 0.1409 - val_acc: 0.9584\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1206 - acc: 0.9649 - val_loss: 0.1390 - val_acc: 0.9587\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1191 - acc: 0.9652 - val_loss: 0.1380 - val_acc: 0.9595\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1178 - acc: 0.9660 - val_loss: 0.1377 - val_acc: 0.9597\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1167 - acc: 0.9664 - val_loss: 0.1355 - val_acc: 0.9597\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1155 - acc: 0.9668 - val_loss: 0.1357 - val_acc: 0.9600\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1139 - acc: 0.9675 - val_loss: 0.1327 - val_acc: 0.9601\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1127 - acc: 0.9675 - val_loss: 0.1342 - val_acc: 0.9599\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1115 - acc: 0.9684 - val_loss: 0.1321 - val_acc: 0.9609\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1104 - acc: 0.9689 - val_loss: 0.1314 - val_acc: 0.9601\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1092 - acc: 0.9690 - val_loss: 0.1317 - val_acc: 0.9605\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1081 - acc: 0.9692 - val_loss: 0.1303 - val_acc: 0.9614\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1069 - acc: 0.9692 - val_loss: 0.1293 - val_acc: 0.9621\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1059 - acc: 0.9699 - val_loss: 0.1290 - val_acc: 0.9614\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1049 - acc: 0.9699 - val_loss: 0.1280 - val_acc: 0.9619\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1037 - acc: 0.9700 - val_loss: 0.1266 - val_acc: 0.9624\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1027 - acc: 0.9704 - val_loss: 0.1274 - val_acc: 0.9616\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1017 - acc: 0.9706 - val_loss: 0.1266 - val_acc: 0.9624\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1007 - acc: 0.9710 - val_loss: 0.1264 - val_acc: 0.9618\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0999 - acc: 0.9710 - val_loss: 0.1248 - val_acc: 0.9623\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0987 - acc: 0.9714 - val_loss: 0.1245 - val_acc: 0.9624\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0977 - acc: 0.9723 - val_loss: 0.1268 - val_acc: 0.9612\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0969 - acc: 0.9720 - val_loss: 0.1227 - val_acc: 0.9618\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0961 - acc: 0.9720 - val_loss: 0.1224 - val_acc: 0.9628\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0951 - acc: 0.9725 - val_loss: 0.1224 - val_acc: 0.9627\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0944 - acc: 0.9724 - val_loss: 0.1217 - val_acc: 0.9629\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0935 - acc: 0.9729 - val_loss: 0.1228 - val_acc: 0.9627\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0927 - acc: 0.9734 - val_loss: 0.1220 - val_acc: 0.9620\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0918 - acc: 0.9737 - val_loss: 0.1203 - val_acc: 0.9630\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0910 - acc: 0.9743 - val_loss: 0.1193 - val_acc: 0.9629\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0902 - acc: 0.9739 - val_loss: 0.1204 - val_acc: 0.9630\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0894 - acc: 0.9742 - val_loss: 0.1200 - val_acc: 0.9627\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0885 - acc: 0.9743 - val_loss: 0.1197 - val_acc: 0.9639\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0877 - acc: 0.9745 - val_loss: 0.1209 - val_acc: 0.9632\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0871 - acc: 0.9745 - val_loss: 0.1176 - val_acc: 0.9631\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0863 - acc: 0.9749 - val_loss: 0.1187 - val_acc: 0.9639\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0857 - acc: 0.9752 - val_loss: 0.1176 - val_acc: 0.9637\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0849 - acc: 0.9756 - val_loss: 0.1179 - val_acc: 0.9627\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0842 - acc: 0.9758 - val_loss: 0.1169 - val_acc: 0.9637\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0834 - acc: 0.9760 - val_loss: 0.1158 - val_acc: 0.9645\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0828 - acc: 0.9758 - val_loss: 0.1163 - val_acc: 0.9643\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0821 - acc: 0.9762 - val_loss: 0.1152 - val_acc: 0.9637\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0813 - acc: 0.9765 - val_loss: 0.1137 - val_acc: 0.9644\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0808 - acc: 0.9767 - val_loss: 0.1161 - val_acc: 0.9645\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0799 - acc: 0.9770 - val_loss: 0.1154 - val_acc: 0.9633\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0795 - acc: 0.9772 - val_loss: 0.1151 - val_acc: 0.9639\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0788 - acc: 0.9771 - val_loss: 0.1140 - val_acc: 0.9653\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0779 - acc: 0.9777 - val_loss: 0.1140 - val_acc: 0.9643\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0776 - acc: 0.9782 - val_loss: 0.1143 - val_acc: 0.9642\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.1129 - val_acc: 0.9647\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0764 - acc: 0.9781 - val_loss: 0.1125 - val_acc: 0.9663\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0755 - acc: 0.9782 - val_loss: 0.1137 - val_acc: 0.9647\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0750 - acc: 0.9787 - val_loss: 0.1122 - val_acc: 0.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0745 - acc: 0.9785 - val_loss: 0.1120 - val_acc: 0.9659\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0738 - acc: 0.9790 - val_loss: 0.1119 - val_acc: 0.9649\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0732 - acc: 0.9790 - val_loss: 0.1125 - val_acc: 0.9651\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0726 - acc: 0.9793 - val_loss: 0.1130 - val_acc: 0.9639\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0720 - acc: 0.9795 - val_loss: 0.1106 - val_acc: 0.9657\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0717 - acc: 0.9795 - val_loss: 0.1116 - val_acc: 0.9650\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0710 - acc: 0.9797 - val_loss: 0.1102 - val_acc: 0.9655\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0706 - acc: 0.9799 - val_loss: 0.1119 - val_acc: 0.9641\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0698 - acc: 0.9800 - val_loss: 0.1100 - val_acc: 0.9653\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0695 - acc: 0.9801 - val_loss: 0.1112 - val_acc: 0.9648\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0690 - acc: 0.9804 - val_loss: 0.1109 - val_acc: 0.9650\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0684 - acc: 0.9804 - val_loss: 0.1100 - val_acc: 0.9655\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0676 - acc: 0.9807 - val_loss: 0.1104 - val_acc: 0.9654\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0673 - acc: 0.9807 - val_loss: 0.1106 - val_acc: 0.9663\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0668 - acc: 0.9810 - val_loss: 0.1098 - val_acc: 0.9661\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0663 - acc: 0.9810 - val_loss: 0.1105 - val_acc: 0.9657\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0658 - acc: 0.9813 - val_loss: 0.1108 - val_acc: 0.9663\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0653 - acc: 0.9815 - val_loss: 0.1107 - val_acc: 0.9653\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0650 - acc: 0.9812 - val_loss: 0.1119 - val_acc: 0.9650\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0644 - acc: 0.9816 - val_loss: 0.1094 - val_acc: 0.9659\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0639 - acc: 0.9820 - val_loss: 0.1095 - val_acc: 0.9654\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0635 - acc: 0.9818 - val_loss: 0.1101 - val_acc: 0.9652\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0629 - acc: 0.9824 - val_loss: 0.1104 - val_acc: 0.9651\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0626 - acc: 0.9823 - val_loss: 0.1093 - val_acc: 0.9663\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0619 - acc: 0.9823 - val_loss: 0.1117 - val_acc: 0.9652\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0617 - acc: 0.9826 - val_loss: 0.1085 - val_acc: 0.9663\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0610 - acc: 0.9826 - val_loss: 0.1099 - val_acc: 0.9658\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0607 - acc: 0.9828 - val_loss: 0.1101 - val_acc: 0.9663\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0603 - acc: 0.9829 - val_loss: 0.1101 - val_acc: 0.9663\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0598 - acc: 0.9830 - val_loss: 0.1096 - val_acc: 0.9653\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0595 - acc: 0.9832 - val_loss: 0.1109 - val_acc: 0.9653\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0589 - acc: 0.9832 - val_loss: 0.1135 - val_acc: 0.9647\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0584 - acc: 0.9837 - val_loss: 0.1106 - val_acc: 0.9657\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0580 - acc: 0.9833 - val_loss: 0.1086 - val_acc: 0.9663\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0577 - acc: 0.9840 - val_loss: 0.1088 - val_acc: 0.9669\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0573 - acc: 0.9837 - val_loss: 0.1101 - val_acc: 0.9655\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0568 - acc: 0.9839 - val_loss: 0.1094 - val_acc: 0.9660\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0564 - acc: 0.9842 - val_loss: 0.1095 - val_acc: 0.9657\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0560 - acc: 0.9842 - val_loss: 0.1092 - val_acc: 0.9672\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0556 - acc: 0.9844 - val_loss: 0.1092 - val_acc: 0.9657\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0551 - acc: 0.9844 - val_loss: 0.1096 - val_acc: 0.9662\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0548 - acc: 0.9849 - val_loss: 0.1096 - val_acc: 0.9651\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0545 - acc: 0.9846 - val_loss: 0.1083 - val_acc: 0.9661\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0540 - acc: 0.9847 - val_loss: 0.1087 - val_acc: 0.9667\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0536 - acc: 0.9848 - val_loss: 0.1097 - val_acc: 0.9652\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0532 - acc: 0.9853 - val_loss: 0.1086 - val_acc: 0.9665\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0528 - acc: 0.9856 - val_loss: 0.1092 - val_acc: 0.9666\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0523 - acc: 0.9857 - val_loss: 0.1098 - val_acc: 0.9668\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0523 - acc: 0.9852 - val_loss: 0.1091 - val_acc: 0.9665\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0518 - acc: 0.9856 - val_loss: 0.1095 - val_acc: 0.9660\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0511 - acc: 0.9860 - val_loss: 0.1107 - val_acc: 0.9667\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0511 - acc: 0.9859 - val_loss: 0.1099 - val_acc: 0.9663\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0504 - acc: 0.9857 - val_loss: 0.1102 - val_acc: 0.9669\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0502 - acc: 0.9861 - val_loss: 0.1096 - val_acc: 0.9657\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0500 - acc: 0.9862 - val_loss: 0.1090 - val_acc: 0.9671\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0495 - acc: 0.9862 - val_loss: 0.1094 - val_acc: 0.9662\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0491 - acc: 0.9864 - val_loss: 0.1104 - val_acc: 0.9657\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0488 - acc: 0.9864 - val_loss: 0.1103 - val_acc: 0.9663\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0485 - acc: 0.9864 - val_loss: 0.1101 - val_acc: 0.9664\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0482 - acc: 0.9866 - val_loss: 0.1113 - val_acc: 0.9666\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0478 - acc: 0.9869 - val_loss: 0.1105 - val_acc: 0.9667\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0474 - acc: 0.9872 - val_loss: 0.1094 - val_acc: 0.9667\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0471 - acc: 0.9871 - val_loss: 0.1109 - val_acc: 0.9659\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0468 - acc: 0.9870 - val_loss: 0.1117 - val_acc: 0.9657\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0465 - acc: 0.9871 - val_loss: 0.1125 - val_acc: 0.9662\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0462 - acc: 0.9873 - val_loss: 0.1110 - val_acc: 0.9671\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0456 - acc: 0.9875 - val_loss: 0.1132 - val_acc: 0.9649\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0456 - acc: 0.9876 - val_loss: 0.1103 - val_acc: 0.9657\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0452 - acc: 0.9875 - val_loss: 0.1118 - val_acc: 0.9657\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0447 - acc: 0.9875 - val_loss: 0.1105 - val_acc: 0.9666\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0445 - acc: 0.9879 - val_loss: 0.1108 - val_acc: 0.9669\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0442 - acc: 0.9879 - val_loss: 0.1114 - val_acc: 0.9672\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0438 - acc: 0.9884 - val_loss: 0.1112 - val_acc: 0.9663\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0435 - acc: 0.9879 - val_loss: 0.1110 - val_acc: 0.9665\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0433 - acc: 0.9882 - val_loss: 0.1120 - val_acc: 0.9654\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0429 - acc: 0.9886 - val_loss: 0.1113 - val_acc: 0.9661\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0426 - acc: 0.9887 - val_loss: 0.1108 - val_acc: 0.9668\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0422 - acc: 0.9886 - val_loss: 0.1130 - val_acc: 0.9658\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0419 - acc: 0.9886 - val_loss: 0.1127 - val_acc: 0.9662\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0418 - acc: 0.9886 - val_loss: 0.1113 - val_acc: 0.9674\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0414 - acc: 0.9888 - val_loss: 0.1130 - val_acc: 0.9652\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0412 - acc: 0.9890 - val_loss: 0.1130 - val_acc: 0.9661\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0408 - acc: 0.9894 - val_loss: 0.1135 - val_acc: 0.9658\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(loss='categorical_crossentropy', optimizer=otimizador, metrics=['acc'])\n",
    "historico = modelo.fit(x_treino_normalizado, y_treino_convertido, epochs=200, batch_size=100, validation_data=(x_teste_normalizado, y_teste_convertido), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_treino = historico.history['acc']\n",
    "acc_teste = historico.history['val_acc']\n",
    "epochs = range(1, len(acc_treino)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc_treino, '-g', \"Acurácia no treino\")\n",
    "plt.plot(epochs, acc_teste, '-b', 'Acurácia no teste')\n",
    "#plt.xlabel(\"epochs\")\n",
    "#plt.ylabel(\"acurácia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rede Neural Artificial #00</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_treino, y_treino),(x_teste, y_teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_convertido = np_utils.to_categorical(y_treino)\n",
    "y_teste_convertido = np_utils.to_categorical(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino_convertido #verificando se converteu corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb57137fc50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_treino[0], cmap='gray') #imprimindo uma das amostras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reshape: Colocando as imagens (amostras) no formato de única linha</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_remodelado = x_treino.reshape((60000,784))\n",
    "x_teste_remodelado = x_teste.reshape((10000,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treino_remodelado.shape #testando se deu certo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Normalizando os dados (entre 0 e 1):</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_normalizado = x_teste_remodelado.astype('float32')/255\n",
    "x_treino_normalizado = x_treino_remodelado.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste_normalizado #verificando se due certo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Criando a minha rede...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(30, input_dim=784, kernel_initializer='normal', activation='relu')) #entrada e primeira camada\n",
    "modelo.add(Dense(30, kernel_initializer='normal', activation='relu')) #segunda camada\n",
    "modelo.add(Dense(10, kernel_initializer='normal', activation='softmax')) #saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 2.2959 - acc: 0.1571 - val_loss: 2.2833 - val_acc: 0.2268\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.2101 - acc: 0.3232 - val_loss: 2.0288 - val_acc: 0.3207\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6458 - acc: 0.4786 - val_loss: 1.2097 - val_acc: 0.6032\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0076 - acc: 0.6890 - val_loss: 0.8231 - val_acc: 0.7509\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.7401 - acc: 0.7707 - val_loss: 0.6283 - val_acc: 0.8024\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5878 - acc: 0.8244 - val_loss: 0.5176 - val_acc: 0.8447\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4949 - acc: 0.8583 - val_loss: 0.4513 - val_acc: 0.8687\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4402 - acc: 0.8751 - val_loss: 0.4128 - val_acc: 0.8811\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4047 - acc: 0.8859 - val_loss: 0.3847 - val_acc: 0.8877\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3803 - acc: 0.8916 - val_loss: 0.3640 - val_acc: 0.8930\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3614 - acc: 0.8966 - val_loss: 0.3471 - val_acc: 0.8978\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3470 - acc: 0.9011 - val_loss: 0.3355 - val_acc: 0.9007\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3346 - acc: 0.9044 - val_loss: 0.3227 - val_acc: 0.9051\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3238 - acc: 0.9070 - val_loss: 0.3162 - val_acc: 0.9077\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3142 - acc: 0.9101 - val_loss: 0.3070 - val_acc: 0.9097\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3056 - acc: 0.9125 - val_loss: 0.2991 - val_acc: 0.9111\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2975 - acc: 0.9147 - val_loss: 0.2906 - val_acc: 0.9147\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2902 - acc: 0.9171 - val_loss: 0.2858 - val_acc: 0.9161\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2829 - acc: 0.9191 - val_loss: 0.2781 - val_acc: 0.9194\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2762 - acc: 0.9208 - val_loss: 0.2716 - val_acc: 0.9215\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2695 - acc: 0.9225 - val_loss: 0.2690 - val_acc: 0.9223\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2631 - acc: 0.9245 - val_loss: 0.2619 - val_acc: 0.9239\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2565 - acc: 0.9262 - val_loss: 0.2558 - val_acc: 0.9243\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2500 - acc: 0.9281 - val_loss: 0.2499 - val_acc: 0.9277\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2437 - acc: 0.9304 - val_loss: 0.2449 - val_acc: 0.9288\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2373 - acc: 0.9318 - val_loss: 0.2392 - val_acc: 0.9304\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2310 - acc: 0.9339 - val_loss: 0.2320 - val_acc: 0.9315\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2246 - acc: 0.9354 - val_loss: 0.2295 - val_acc: 0.9322\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2192 - acc: 0.9370 - val_loss: 0.2229 - val_acc: 0.9335\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2132 - acc: 0.9387 - val_loss: 0.2181 - val_acc: 0.9366\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2080 - acc: 0.9408 - val_loss: 0.2135 - val_acc: 0.9369\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2027 - acc: 0.9425 - val_loss: 0.2073 - val_acc: 0.9391\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1976 - acc: 0.9434 - val_loss: 0.2033 - val_acc: 0.9395\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1929 - acc: 0.9453 - val_loss: 0.1999 - val_acc: 0.9407\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1885 - acc: 0.9462 - val_loss: 0.1959 - val_acc: 0.9417\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1842 - acc: 0.9476 - val_loss: 0.1923 - val_acc: 0.9429\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1800 - acc: 0.9485 - val_loss: 0.1894 - val_acc: 0.9432\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1764 - acc: 0.9503 - val_loss: 0.1831 - val_acc: 0.9446\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1724 - acc: 0.9511 - val_loss: 0.1818 - val_acc: 0.9453\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1691 - acc: 0.9517 - val_loss: 0.1787 - val_acc: 0.9462\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1657 - acc: 0.9527 - val_loss: 0.1750 - val_acc: 0.9474\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1626 - acc: 0.9536 - val_loss: 0.1728 - val_acc: 0.9482\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1594 - acc: 0.9539 - val_loss: 0.1697 - val_acc: 0.9489\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1566 - acc: 0.9552 - val_loss: 0.1672 - val_acc: 0.9496\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1538 - acc: 0.9561 - val_loss: 0.1638 - val_acc: 0.9509\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1511 - acc: 0.9567 - val_loss: 0.1624 - val_acc: 0.9516\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1483 - acc: 0.9574 - val_loss: 0.1613 - val_acc: 0.9516\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1458 - acc: 0.9579 - val_loss: 0.1588 - val_acc: 0.9527\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1434 - acc: 0.9588 - val_loss: 0.1561 - val_acc: 0.9528\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1409 - acc: 0.9595 - val_loss: 0.1543 - val_acc: 0.9532\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1389 - acc: 0.9602 - val_loss: 0.1544 - val_acc: 0.9539\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1365 - acc: 0.9605 - val_loss: 0.1513 - val_acc: 0.9541\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1344 - acc: 0.9613 - val_loss: 0.1499 - val_acc: 0.9556\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1323 - acc: 0.9619 - val_loss: 0.1488 - val_acc: 0.9560\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1307 - acc: 0.9622 - val_loss: 0.1474 - val_acc: 0.9565\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1285 - acc: 0.9635 - val_loss: 0.1448 - val_acc: 0.9569\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1267 - acc: 0.9637 - val_loss: 0.1434 - val_acc: 0.9585\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1249 - acc: 0.9640 - val_loss: 0.1425 - val_acc: 0.9577\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1234 - acc: 0.9647 - val_loss: 0.1419 - val_acc: 0.9587\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1217 - acc: 0.9653 - val_loss: 0.1395 - val_acc: 0.9588\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1200 - acc: 0.9658 - val_loss: 0.1379 - val_acc: 0.9597\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1184 - acc: 0.9661 - val_loss: 0.1374 - val_acc: 0.9590\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1168 - acc: 0.9667 - val_loss: 0.1370 - val_acc: 0.9604\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1154 - acc: 0.9669 - val_loss: 0.1366 - val_acc: 0.9603\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1139 - acc: 0.9675 - val_loss: 0.1363 - val_acc: 0.9598\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1125 - acc: 0.9677 - val_loss: 0.1327 - val_acc: 0.9604\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1111 - acc: 0.9687 - val_loss: 0.1326 - val_acc: 0.9614\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1098 - acc: 0.9689 - val_loss: 0.1309 - val_acc: 0.9614\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1082 - acc: 0.9695 - val_loss: 0.1306 - val_acc: 0.9610\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1073 - acc: 0.9696 - val_loss: 0.1295 - val_acc: 0.9626\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1060 - acc: 0.9699 - val_loss: 0.1294 - val_acc: 0.9622\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1047 - acc: 0.9708 - val_loss: 0.1276 - val_acc: 0.9622\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1036 - acc: 0.9712 - val_loss: 0.1254 - val_acc: 0.9645\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1022 - acc: 0.9713 - val_loss: 0.1249 - val_acc: 0.9640\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1012 - acc: 0.9716 - val_loss: 0.1237 - val_acc: 0.9646\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0999 - acc: 0.9717 - val_loss: 0.1239 - val_acc: 0.9641\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0988 - acc: 0.9720 - val_loss: 0.1223 - val_acc: 0.9654\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0978 - acc: 0.9725 - val_loss: 0.1215 - val_acc: 0.9636\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0964 - acc: 0.9728 - val_loss: 0.1238 - val_acc: 0.9645\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0956 - acc: 0.9732 - val_loss: 0.1211 - val_acc: 0.9657\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0946 - acc: 0.9728 - val_loss: 0.1210 - val_acc: 0.9656\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0935 - acc: 0.9737 - val_loss: 0.1195 - val_acc: 0.9653\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0923 - acc: 0.9738 - val_loss: 0.1201 - val_acc: 0.9654\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0915 - acc: 0.9740 - val_loss: 0.1188 - val_acc: 0.9650\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0905 - acc: 0.9747 - val_loss: 0.1185 - val_acc: 0.9660\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.9745 - val_loss: 0.1193 - val_acc: 0.9653\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0883 - acc: 0.9754 - val_loss: 0.1183 - val_acc: 0.9648\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0878 - acc: 0.9749 - val_loss: 0.1159 - val_acc: 0.9663\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0867 - acc: 0.9751 - val_loss: 0.1161 - val_acc: 0.9655\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0860 - acc: 0.9756 - val_loss: 0.1154 - val_acc: 0.9665\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0852 - acc: 0.9759 - val_loss: 0.1135 - val_acc: 0.9671\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0840 - acc: 0.9765 - val_loss: 0.1153 - val_acc: 0.9675\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0834 - acc: 0.9764 - val_loss: 0.1138 - val_acc: 0.9669\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0827 - acc: 0.9764 - val_loss: 0.1140 - val_acc: 0.9668\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0817 - acc: 0.9770 - val_loss: 0.1132 - val_acc: 0.9664\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0812 - acc: 0.9766 - val_loss: 0.1111 - val_acc: 0.9674\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0801 - acc: 0.9773 - val_loss: 0.1120 - val_acc: 0.9673\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0793 - acc: 0.9771 - val_loss: 0.1112 - val_acc: 0.9674\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0789 - acc: 0.9776 - val_loss: 0.1115 - val_acc: 0.9675\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0779 - acc: 0.9775 - val_loss: 0.1122 - val_acc: 0.9665\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0774 - acc: 0.9779 - val_loss: 0.1114 - val_acc: 0.9673\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0768 - acc: 0.9780 - val_loss: 0.1110 - val_acc: 0.9665\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0757 - acc: 0.9784 - val_loss: 0.1118 - val_acc: 0.9670\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0753 - acc: 0.9784 - val_loss: 0.1096 - val_acc: 0.9684\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0746 - acc: 0.9781 - val_loss: 0.1093 - val_acc: 0.9668\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0741 - acc: 0.9789 - val_loss: 0.1094 - val_acc: 0.9674\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0734 - acc: 0.9791 - val_loss: 0.1090 - val_acc: 0.9677\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0726 - acc: 0.9793 - val_loss: 0.1097 - val_acc: 0.9673\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0720 - acc: 0.9788 - val_loss: 0.1091 - val_acc: 0.9683\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0715 - acc: 0.9796 - val_loss: 0.1091 - val_acc: 0.9680\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0709 - acc: 0.9796 - val_loss: 0.1087 - val_acc: 0.9679\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0704 - acc: 0.9796 - val_loss: 0.1108 - val_acc: 0.9670\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0698 - acc: 0.9795 - val_loss: 0.1092 - val_acc: 0.9678\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0690 - acc: 0.9801 - val_loss: 0.1085 - val_acc: 0.9672\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0685 - acc: 0.9804 - val_loss: 0.1090 - val_acc: 0.9678\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0680 - acc: 0.9807 - val_loss: 0.1097 - val_acc: 0.9672\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0673 - acc: 0.9810 - val_loss: 0.1078 - val_acc: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0670 - acc: 0.9806 - val_loss: 0.1073 - val_acc: 0.9680\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0665 - acc: 0.9812 - val_loss: 0.1080 - val_acc: 0.9678\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0658 - acc: 0.9809 - val_loss: 0.1074 - val_acc: 0.9677\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0653 - acc: 0.9814 - val_loss: 0.1085 - val_acc: 0.9679\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0647 - acc: 0.9815 - val_loss: 0.1077 - val_acc: 0.9683\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0643 - acc: 0.9820 - val_loss: 0.1082 - val_acc: 0.9677\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0640 - acc: 0.9820 - val_loss: 0.1069 - val_acc: 0.9684\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0633 - acc: 0.9821 - val_loss: 0.1069 - val_acc: 0.9676\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0629 - acc: 0.9819 - val_loss: 0.1058 - val_acc: 0.9680\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0622 - acc: 0.9822 - val_loss: 0.1069 - val_acc: 0.9679\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0619 - acc: 0.9821 - val_loss: 0.1062 - val_acc: 0.9684\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9826 - val_loss: 0.1076 - val_acc: 0.9677\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0608 - acc: 0.9828 - val_loss: 0.1068 - val_acc: 0.9684\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0604 - acc: 0.9826 - val_loss: 0.1072 - val_acc: 0.9677\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0601 - acc: 0.9824 - val_loss: 0.1069 - val_acc: 0.9679\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0597 - acc: 0.9829 - val_loss: 0.1070 - val_acc: 0.9689\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0591 - acc: 0.9829 - val_loss: 0.1064 - val_acc: 0.9688\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0588 - acc: 0.9833 - val_loss: 0.1058 - val_acc: 0.9693\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0582 - acc: 0.9833 - val_loss: 0.1071 - val_acc: 0.9686\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0578 - acc: 0.9833 - val_loss: 0.1079 - val_acc: 0.9679\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0574 - acc: 0.9836 - val_loss: 0.1074 - val_acc: 0.9687\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0569 - acc: 0.9837 - val_loss: 0.1066 - val_acc: 0.9683\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0566 - acc: 0.9837 - val_loss: 0.1068 - val_acc: 0.9683\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0561 - acc: 0.9841 - val_loss: 0.1065 - val_acc: 0.9684\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0557 - acc: 0.9841 - val_loss: 0.1072 - val_acc: 0.9680\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0552 - acc: 0.9843 - val_loss: 0.1072 - val_acc: 0.9682\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0549 - acc: 0.9844 - val_loss: 0.1063 - val_acc: 0.9691\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0545 - acc: 0.9843 - val_loss: 0.1066 - val_acc: 0.9688\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0541 - acc: 0.9850 - val_loss: 0.1063 - val_acc: 0.9686\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0537 - acc: 0.9848 - val_loss: 0.1073 - val_acc: 0.9688\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0534 - acc: 0.9849 - val_loss: 0.1069 - val_acc: 0.9688\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0530 - acc: 0.9847 - val_loss: 0.1063 - val_acc: 0.9689\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0524 - acc: 0.9854 - val_loss: 0.1071 - val_acc: 0.9686\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0521 - acc: 0.9853 - val_loss: 0.1065 - val_acc: 0.9687\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0518 - acc: 0.9851 - val_loss: 0.1073 - val_acc: 0.9681\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0514 - acc: 0.9855 - val_loss: 0.1061 - val_acc: 0.9686\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0510 - acc: 0.9856 - val_loss: 0.1061 - val_acc: 0.9684\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0506 - acc: 0.9861 - val_loss: 0.1075 - val_acc: 0.9687\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0504 - acc: 0.9860 - val_loss: 0.1067 - val_acc: 0.9686\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0501 - acc: 0.9861 - val_loss: 0.1063 - val_acc: 0.9687\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0496 - acc: 0.9857 - val_loss: 0.1084 - val_acc: 0.9682\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0494 - acc: 0.9860 - val_loss: 0.1077 - val_acc: 0.9683\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0488 - acc: 0.9864 - val_loss: 0.1122 - val_acc: 0.9680\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0487 - acc: 0.9861 - val_loss: 0.1070 - val_acc: 0.9692\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0482 - acc: 0.9866 - val_loss: 0.1093 - val_acc: 0.9688\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0479 - acc: 0.9867 - val_loss: 0.1084 - val_acc: 0.9679\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0475 - acc: 0.9868 - val_loss: 0.1080 - val_acc: 0.9676\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0471 - acc: 0.9869 - val_loss: 0.1084 - val_acc: 0.9679\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0469 - acc: 0.9869 - val_loss: 0.1074 - val_acc: 0.9684\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0464 - acc: 0.9872 - val_loss: 0.1084 - val_acc: 0.9683\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0463 - acc: 0.9871 - val_loss: 0.1082 - val_acc: 0.9682\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0459 - acc: 0.9873 - val_loss: 0.1076 - val_acc: 0.9681\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0454 - acc: 0.9876 - val_loss: 0.1101 - val_acc: 0.9672\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0452 - acc: 0.9875 - val_loss: 0.1076 - val_acc: 0.9689\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0449 - acc: 0.9875 - val_loss: 0.1085 - val_acc: 0.9688\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0446 - acc: 0.9877 - val_loss: 0.1078 - val_acc: 0.9686\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0444 - acc: 0.9875 - val_loss: 0.1104 - val_acc: 0.9681\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0440 - acc: 0.9879 - val_loss: 0.1083 - val_acc: 0.9690\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0436 - acc: 0.9877 - val_loss: 0.1086 - val_acc: 0.9694\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0434 - acc: 0.9878 - val_loss: 0.1092 - val_acc: 0.9681\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0433 - acc: 0.9880 - val_loss: 0.1080 - val_acc: 0.9682\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0427 - acc: 0.9879 - val_loss: 0.1082 - val_acc: 0.9690\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0424 - acc: 0.9881 - val_loss: 0.1109 - val_acc: 0.9673\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0422 - acc: 0.9880 - val_loss: 0.1094 - val_acc: 0.9682\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0418 - acc: 0.9886 - val_loss: 0.1090 - val_acc: 0.9685\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0418 - acc: 0.9886 - val_loss: 0.1089 - val_acc: 0.9686\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0413 - acc: 0.9885 - val_loss: 0.1098 - val_acc: 0.9683\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0410 - acc: 0.9887 - val_loss: 0.1096 - val_acc: 0.9683\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0410 - acc: 0.9887 - val_loss: 0.1093 - val_acc: 0.9689\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0405 - acc: 0.9886 - val_loss: 0.1107 - val_acc: 0.9685\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0403 - acc: 0.9888 - val_loss: 0.1105 - val_acc: 0.9682\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0399 - acc: 0.9891 - val_loss: 0.1097 - val_acc: 0.9683\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0396 - acc: 0.9893 - val_loss: 0.1103 - val_acc: 0.9690\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0393 - acc: 0.9893 - val_loss: 0.1099 - val_acc: 0.9691\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0392 - acc: 0.9891 - val_loss: 0.1103 - val_acc: 0.9689\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0389 - acc: 0.9895 - val_loss: 0.1100 - val_acc: 0.9686\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0386 - acc: 0.9894 - val_loss: 0.1108 - val_acc: 0.9686\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0385 - acc: 0.9894 - val_loss: 0.1098 - val_acc: 0.9696\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0381 - acc: 0.9891 - val_loss: 0.1119 - val_acc: 0.9682\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0379 - acc: 0.9897 - val_loss: 0.1103 - val_acc: 0.9690\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0377 - acc: 0.9899 - val_loss: 0.1108 - val_acc: 0.9688\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0374 - acc: 0.9901 - val_loss: 0.1114 - val_acc: 0.9688\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0371 - acc: 0.9900 - val_loss: 0.1119 - val_acc: 0.9686\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(loss='categorical_crossentropy', optimizer=otimizador, metrics=['acc'])\n",
    "historico = modelo.fit(x_treino_normalizado, y_treino_convertido, epochs=200, batch_size=100, validation_data=(x_teste_normalizado, y_teste_convertido), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_treino = historico.history['acc']\n",
    "acc_teste = historico.history['val_acc']\n",
    "epochs = range(1, len(acc_treino)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XucXHV9//HXZ25732zuCUkgCQQhgAaMeAFFC0VCFezFAtafirQ8aEu1VVvtQ4uo/fkQf61WCj+V1ihaFdEWpf6giNZ65ZKABCQxJAQIm+tmk81mb3P9/P74nt1MNrObySYzs5t5Px+PecycM9855zNnZ7+f8/2ec77H3B0RERGAWK0DEBGRyUNJQURERigpiIjICCUFEREZoaQgIiIjlBRERGSEkoLIMTCzk82sz8ziVVjXu8zs5xVc/v1m9s6i6b83sz1mtrOa31NqS0lBJszM3mZma6PKYkdUqVwYvXezmbmZvbWofCKatzia/ko0fX5RmdPMbMyLZ8xshpndY2b9ZvaCmb2tREwvRO9/18xmjLMsN7NdZpYYFePu8WIo5u5b3b3V3fPjlSu3QjezN5rZT83sgJl1mdlPzOyKcmI5Vu6+yt3vjOJYBLwfWO7u88r9njL1KSnIhJjZ+4B/Aj4JzAVOBv4vcGVRsb3Ax4+wd7kX+PujWPXtQCZa5x8Bnzezs6KYzgK+CPyv6P2BKKbx9ACriqYvB/YdRTzHjZn9AfBt4KvAQsJ3uAl4cw3COQXodvfdx7qg4qQrU4C766HHUT2AaUAf8NZxytwMfB1YB7wzmpcAHFgcTX8F+AywE7gomnda+FmWXGYLISGcXjTva8CnotefBL5R9N6pUfm2MZbnwEeAbxfN+w7w4eIYgP8BPgH8AjgA/ACYFb23OFpOIpp+F7AlKvccIXGdCQwB+Wi79ZSIxYCtwF+Ps03fBfy8aPpzwItAL/AY8Nqi984H1kbv7QI+E81vBP4N6CYkxDXA3KLv+cfAJcAgUIji/UqJ7zkN+BKwA9hGSOzxojh/AXyWKOnX+jerR/kPtRRkIl5NqFzuOUI5B/4O+KiZJccoM0CozP93Ges9Hci7+zNF89YBZ0Wvz4qmw8rdnyVKIuMs87vA68ysw8w6gNcC3ytR7m3AtcAcIAV8YHQBM2sBbgVWuXsb8BrgCXffANwAPOShC6ajxPJfAiwiJKVyrQFWADOAbwDfNrPG6L3PAZ9z93ZCcrw7mv9OQoW+CJgZxTVYvFB3/yGh9bQ9ivddJdZ9J5AjJPFzgUsJCWXYKwnJcQ7l/W1lklBSkImYCexx99yRCrr7vUAXh1YYo30RONnMVo1TBqAV2D9q3n6grcz3SxkC/hO4CrgauDeaN9qX3f0Zdx8kVLArxlheATjbzJrcfYe7Pz3OuovNjJ53lFked/83d+9295y7/yPQQEguAFngNDOb5e597v5w0fyZwGnunnf3x9y9t9x1ApjZXELS+Et37/fQxfRZwvYbtt3d/zmKbbDkgmRSUlKQiegGZh1FX/FHCF0yjaXedPc0oXvmE4RulLH0Ae2j5rUTumrKeX8sXwXeET2+OkaZnUWvBwgJ6BDu3k9ILjcAO8zs/5nZGUdY97Du6Hl+meUxs/eb2QYz229mPYQWwKzo7esILaTfmNkaM3tTNP9rwAPAXWa23cw+PU4rbiynAEnCd+yJ1v1FQqtg2ItHuUyZJJQUZCIeIuxNv6Wcwu7+ILAZ+LNxin2ZUKn97jhlngESZrasaN7LgOG98aejaQDMbClh77m4u6mUnxEq47nAMZ3y6e4PuPtvR8v7DfAvw28d4aMbCRXp75ezHjN7LfBB4A+B6VGX1H6ipOrum9z9GkJFfQvwHTNrcfesu3/M3ZcTurfeREiGR+NFIE04rtIRPdrd/ayiMhp+eYpSUpCj5u77CWfF3G5mbzGzZjNLmtkqM/v0GB/7MPA34ywzRzg4/cFxyvQD/0E4o6nFzC4gnO30tajI14E3m9lro/79jwP/4e7jthTc3Qln+FwRvZ4QM5trZldE604TWi7Dp3DuAhaaWWqcGN4H/J2ZXWtm7WYWM7MLzeyOEh9pI/TpdxES5U0UtZLM7O1mNtvdC4QDygB5M3uDmZ0TnRHWS+hOOqrTTN19B+Fg+z8WxXmqmV10NMuRyUlJQSbE3T9DqMQ+QqiYXgRuJBy4LVX+F8CjR1jsNzlyn/qfAU3A7qj8nw7320fPNxCSw25CxTle66Q4vqePov9/LDHCuf3bCWfdXFS0/v8mtGR2mtmeMWL4DqH76d3RMnYRzuopdeD7AeB+QivoBULLrbjL5jLgaTPrIxx0vtrdh4B5hIPZvcAG4CeEs5GO1jsIB9zXE07h/Q5H0fUlk5cdw46RiIicYNRSEBGREUoKIiIyQklBRERGKCmIiMiIKTdQ1axZs3zx4sW1DkNEZEp57LHH9rj77COVm3JJYfHixaxdu7bWYYiITClm9kI55dR9JCIiI5QURERkhJKCiIiMqFhSMLPV0W0Nfz3G+2Zmt5rZZjN70szOq1QsIiJSnkq2FL5CGH9lLKuAZdHjeuDzFYxFRETKULGk4O4/JQwKNpYrga968DDQYWYaUEtEpIZqeUxhAYeO6tgZzTuMmV1vZmvNbG1XV1dVghMRqUe1vE6h1B22Sg7Z6u53AHcArFy5UsO6ikhVuTu5gpOPHrmCUxh+Hn4v7+TdyRcKI2ULBci7k8kVyOQKZPMF0rkCMYNE3DgwlCNfcBLxGMmYkYjHiMegL53nwFCW/nSOXMFxh0LBef1L5nDOwmkV/a61TAqdhJuHD1tIGENeRCa54Uoyl3eyhQK5vJPLF8gWnGxU+WXzTjZfIFcokMk5uUIBgFQ8xt7+DPsHsziECs8dh5GKNpcvjCw/XwjLzRfC8sLzwco3lCl6rxB9JppfvKxcofjzYbr4vVxUsRsQM8OMULlPkl3R6S2pEzop3AvcaGZ3Aa8E9kd3dBKpK+6hkorZwYoI4EA6x/6BLPsHs/Slcwxkcgxk8qTiMeIxo7svgxmkEjH60jn6hnL0pXMcGMqRyRcIt0oJe5mHVLzuDKTz9KVz9GdyJOMxGpNxGhIxDgxlR/Zec4WDFWc+72TyTjqXJx3t9VZTMm4kYjESMSMRN+KxGMm4EY9ZNG/Ue7HwXlMyTrwhUVQ2FpUxkrEY8bhFZQ8uLx4Lf4CCh2SQiObFzYjHw/piZgfnR3HFYsXzQpnwGlLxOKlEjFQirMcdcgWntSFOIhYjFyWx4aTU2hCnrTFJa0OCRNwwbOT3UWkVSwpm9k3g9YQbvHcCHyXc7Bt3/wJwH3A54d69A8C1lYpFZLRCwTEDi/7JcvkC/Zk8/ekce/sz7OlLAxCPhX/gfQMZMrkCTak4e/sz9KVzNCTi9KdDRZzJFcjkQ2UZKs1QeaazhZGKNDzyDGULpLN5UokYTak4u3vTpI9TJRszaGlI0JCIASHBGGDDCYfwnVsa4rQ2JGhJJcgVCuwfzJLO5mlrTDCvvZFEVAnHo4o2EVV+jckYDYk4qbiRjMdCt0f8YMWciodKNxmPRY/hckYqHsOBTK5AR3OSjubUwUQIYBC3Qyv44RikeiqWFKKbho/3vgN/Xqn1y4nD3cnkCwxmor3baC93IJOLKuVQmfdncrhDcyrOzt4hunrTZKPug750jh37hyh42Pvd3jOIESrHwWyoqCeqIRGjIREjlYgXvY5Fr+O0NCSY3hzmNSbjIxVrJl9gIJ1jTnsj7Y2JaG/+4B59e2OCaU1JpjUlaW1M0JxK0JSMR10yzsyWcLvndK5AW2OC1oYEzan4SKITmYgpNyCeTF35gtM3lKN3KEvvUJat3QNs3z/EQDpHfyYfVfLhed9Ahhe6B9g3kCGdG+4KKV8qHmNOe8PInmtTMs5ps1tDU9yMVWeHs58PDGVpToWKu7UhQWvSmZMYZHZjjnzjdHLxVtyM6c0pGuKQ7dnOtFRo3mcyORqSMVJNrdA2H/IZyA5AY0cIom83bP8VNM+E+S8N7w32QKYfUs0wtB/2d0KyGZo6wueapkMhB73bobE9nB84sAMa2iE3BNseh0QjtMyCQgPEU4BBf39Ybj4b3ssNhXW1zYdECtJ9YLEwf2h/KGNx6O8K626YFuLb9zz07Qpl0wfCd2qbD+0nQUMb9G4L8cUbQhxmoW+qoQ1i8fCZnhdCLMmm8N1iifCZkUceEg3hvVRLKGcxGNwXtlssCZ4/WD6fC2WapofvG0tAIQu714fv1dQBHSdD20lhu+YzkB2C7CDkBsMyYonwSDbDtIWwZ1P4fCwRlploCMtPH4CerTDUE6bnnhXKDOwN22r+S8N6erZCpg9y6bBNh5cTT4bvkemDVGv4uyWbQgwD3dC/J2wzi4XneCo8vAB7nwufn3t2WP9Qb5iOJw9+78UXwpwzj9e/ZElKCjIhA5kcz+3pH6nE+9N5uvvT7DmQpqsvTdeBDD0DGXqjPuoDUX/3WFKJGC2pOM2pBC1Rf+qrl87kJYntnNq/Dk+10hgv0FboI9Y0jZb8ftoHtpKb+1IS006iufdZGns2wUA3eUuQSDURSzSECjHeEP5x924BT0LrXIjNDv+Ee5+FtnmQy4R/9APbwz/oMIuFiiTZFCq67MDIWw3FXyDRFNaBh/KFXKicpjKLhwopNzSRDzPGyYTHl8VDAjmuy4yFJJc+cOhvodIa2kNSzw2OXeZNn1VSkOoayOTY3jPIjv1D7O4NFfzu3jS7DwzRdSBNd3+G/nSOnb1DIwcyAyNOnjYbZF4znNnUw+JGp9A2naVtncz1PTQm4jREXSeNcWdWfhftub3EU03Eko3hn3DrQ2Gvd6gBDiTC3tVYGqfBpm8dnG47CdrmEs9nwx5cPh0q+3w67H3OWBoq6q0Phb349pNg9plhzzjREPbCOk6G1jmhYh/ohnRv2OPMDoSKf+bS8J6FPnvMwp733ufCnn2qNexNx5NhD3v+y8K6un4T/umbOsLnM/3Q0BrWlx0Ke4aDPeHZ4tA+P+wF5zOhpZHpC99xwcpQUfV3hb3lfDZMp1oO7pUP7AmJsKkDeneESjPVEsrFG0Kc/XvC/JY5B/dsE43QsShsRy+ERAghpt7t4e/TviBsq9xQ2MbDhnrDbyHZBNMWhUo1lw7bbXhPPZ4MzxY7+F6mP2xfz4c9c4uF7zy8Z2/x8JwdCHEOtzTMYOZp4TeQ7oV9L4TtnB0Ie9XJxrA9Eo3h88Mtj6He0JLpOAUWvDzEns+EGAb3hb9J+0KIJ0Js3ZtDS6hxGjTPgM61odz0xeHvObzT4fnwt8hnQ9mG1vD59IEQk8XD37FldtS6KoTvUciG9bsfbCXuez6Ubew4uHNRyIYWU6rlOPyXj8/8aNvlNbZy5UrX/RQmxt3p7s+wbd8g23sG2Tb82DfI9v3hed9A9rDPzU5leF3zVpY27GdOcoAOG2BWYpD5dDNz7+PE8hnyTTNJ9u/ACod/fkxNM0LFnM+GSiaehEWvjLo/omb5rJfAS1ZFFUv8YBM/1Rpedz8bKq1Zy8I/o4iUZGaPufvKI5VTS+EEks0X2NEzRGfPANt7hg6p/Ief07kCKbIss04W2B5mJ4Y4oyXOW5K7WdC+l7bpWVpjWZoLfTQO7Sae7cMy/TDkMNKLYKECbpkNZ6yCxmnE+7vCXmbLnLD3NO3ksEc5sAdmLoOZp3LI9YpmB/dEj1bT9IOvZ502wa0lIqUoKUxRmVyBLXv6eGZXH5t2HeCpbft5ZMteBrOhf7WZIZbYTlY0d/Gmhl0sTnQzd0Y3M3J7aBvaRqx4j34QSCfDAbhEa6isG2ZB20tD5d/UEZraM5YePCgZ06jrIiciJYUpomcgw8Nb9vLwlm4e3tLN5t19dBR6OD32IrNjBzi/ZYD3zdrKwsI22oZ2kExHZ3LkgcFY6CduPwnaV8CM3w193dOXhEreYqH/O56s6XcUkdpTUpikDgxlWfP8Xh56tpsnN73A/K6fMpd9LI3v4w+bdnBK81ZacvsOfiANNCyA2WdAxyvDAcwZS0Kf/Iyl4cCbiMgRKClMEvmC89S2/fxkYxe/eGYHJ21/gGtiP+SPrIcP2h4SyXA6pyebsZlnwNzfCeczzzkztAKapkPr7Bp/CxGZ6pQUamh37xCPrnuSrvU/JbtjPQvzL7LKtvFnsV0kEzkG2k+lYdGFxDsWwplXwJwzsGQz6IpVEakQJYUqyuQKrH2+m84197L42W9wcvZZ3mShC6hAjIH2RaTmn0Ny7lvh5FfRvOyNOqArIlWlpFBJmQF2bfgFW555iszWNczq3cBi9vMa20tXfC57570Glq5k7jlvIDZnOa2JhiMvU0SkgpQUjrN0Ls+6xx+m8aF/Ytm+nzCXNHOBPprZ0X42NuMc0me+ntmveAezdbaPiEwySgrHgbvz5DOb2f/DzzCz62FW+nMM0sAv2y4lv+yNnHn2y1m4+HSWxbW5RWRyUy11DHp2beWxB+8i8/xDXJB9iGbSbGl5Gc8vvZGTfvs9XDxtTq1DFBE5KkoKR8udbb+8i8xDd7Ck73EuBvbHptGz4PXEf+fvOH3BWbWOUERkwpQUjsILWzZy4Nt/ztmDa3jRZ3Pf7Hdz5m+9jSVnrmSaThMVkROAkkIZvK+LF775VyzovI8sCX586t+w4vfez+WtukpYRE4sSgpH0P/cI6S//nbmZ/fxg9YrOf+aD/OGhRqZU0ROTEoK49j3szto+dHfss87ePC81fzBm9+sm4iLyAlNSWEMvQ98kukP3cIveSnJq77MVcvVOhCRE5+SQikPf572h27hu4XXcsYNX+OMk6Yf+TMiIicADawz2oGd5B+8mR/mz6Xzdf+ghCAidUUthdF+9o+Qz7C69XpWX7Ss1tGIiFSVWgrF9nfia7/Mt3IXcemFr6YxGa91RCIiVaWkUGzD97FCltV+JVeuWFDraEREqk7dR0Xyz/4325jHS856GdNbUrUOR0Sk6tRSGJbP4s/9nJ/kzuYPzltY62hERGpCSWFY5xoSuX5+XjiblYt1xpGI1CclhWHP/pgCMbZ1rKStUTe/EZH6pKQw7Lmf8pvYqZy84KRaRyIiUjNKCgDu+O71rM0s5qyTptU6GhGRmlFSAOjvwtK9bPH5LJ/fXutoRERqRkkBYM8mALb4fM46SUlBROqXkgJAd0gK+5oWM6ddN84RkfqlpACwZxNpUkyfv6TWkYiI1JSSAkD3Zl5gHifPaq11JCIiNaWkABS6NrEpP48FHc21DkVEpKYqmhTM7DIz22hmm83sQyXeP9nMfmxmvzKzJ83s8krGU1Iug/U8zxY/iQXTm6q+ehGRyaRiScHM4sDtwCpgOXCNmS0fVewjwN3ufi5wNfB/KxXPmPY9j3meLYX5LOjQQWYRqW+VbCmcD2x29y3ungHuAq4cVcaB4XNApwHbKxhPad2bgXA6qrqPRKTeVTIpLABeLJrujOYVuxl4u5l1AvcBf1FqQWZ2vZmtNbO1XV1dxzfKfc8DsD02jzltDcd32SIiU0wlk4KVmOejpq8BvuLuC4HLga+Z2WExufsd7r7S3VfOnj37+EbZs5Uha6KpfTaxWKmQRUTqRyWTQiewqGh6IYd3D10H3A3g7g8BjcCsCsZ0uJ6t7IrPZcF0dR2JiFQyKawBlpnZEjNLEQ4k3zuqzFbgYgAzO5OQFI5z/9AR9GzlxfwsTurQmUciIhVLCu6eA24EHgA2EM4yetrMPm5mV0TF3g/8iZmtA74JvMvdR3cxVZT3vMCzuRk6HVVEhArfo9nd7yMcQC6ed1PR6/XABZWMYVyDPVi6lxcLszldLQURkTq/orlnKwCdPlstBRERlBQA6PRZzJumC9dERJQUCC2FWS26RkFEpO6TQibWzIFYG22NFT28IiIyJdR3Tdizlb2peUyPpXThmogIaimwOzaH6c2pWkciIjIp1HdSGNhDl09jRouSgogI1Hv3UWaAXk8pKYiIROo3KbhDtp99nmC6koKICFDPSSGfgUKOfbkkM3RMQUQEqOdjCpl+APq8Qd1HIiKR+k0K2QEABmhUUhARidRvUsiEpDDoDTqmICISqd+kkA3dRwM06JiCiEikfpNC5mBSmN6SrHEwIiKTQx0nhYPdRzM1GJ6ICFDPSSHqPsolmmlKxWscjIjI5FC/SSFqKaSaWmsciIjI5FG/SSE6JbWhua3GgYiITB71mxSiA83NLUoKIiLD6j4ptCgpiIiMqN+kkB1gkAaaGnQ6qojIsPpNCpl+BmikIVG/m0BEZLT6rRGzAwx4Aw1JnY4qIjKsbpOCZ/pDUlBLQURkRN3WiJ4ZYAAlBRGRYnVbI3q6L2opqPtIRGRY/SaFTD8DNJBSS0FEZMQRa0Qzu9HMplcjmKrKDujsIxGRUcqpEecBa8zsbjO7zMys0kFVRWb47CMlBRGRYUesEd39I8Ay4EvAu4BNZvZJMzu1wrFVlOXCxWs6piAiclBZu8nu7sDO6JEDpgPfMbNPVzC2ynEnltXZRyIioyWOVMDM3gO8E9gD/Cvw1+6eNbMYsAn4m8qGWAG5NOZ5nX0kIjLKEZMCMAv4PXd/oXimuxfM7E2VCavComGzB3X2kYjIIcqpEe8D9g5PmFmbmb0SwN03VCqwiopGSO3X2UciIocop0b8PNBXNN0fzZu6sgfvz6yzj0REDiqnRrToQDMQuo0or9tp8opaCgM6+0hE5BDlJIUtZvYeM0tGj/cCWyodWEVFLQVdvCYicqhyasQbgNcA24BO4JXA9ZUMquKilsKgRkkVETlEORev7Xb3q919jrvPdfe3ufvuchYeXQG90cw2m9mHxijzh2a23syeNrNvHO0XmJCi7iOdfSQiclA51yk0AtcBZwGNw/Pd/d1H+FwcuB34bUILY42Z3evu64vKLAP+FrjA3feZ2ZwJfYujdUj3kY4piIgMK2c3+WuE8Y/eCPwEWAgcKONz5wOb3X2Lu2eAu4ArR5X5E+B2d98HoVVSbuDHJDcEQJokyfiJMZSTiMjxUE5SOM3d/w7od/c7gd8BzinjcwuAF4umO6N5xU4HTjezX5jZw2Z2WakFmdn1ZrbWzNZ2dXWVseojyGfDchMpTpTx/UREjodykkI2eu4xs7OBacDiMj5Xqrb1UdMJwmB7rweuAf7VzDoO+5D7He6+0t1Xzp49u4xVH0E+A0As3nDsyxIROYGUkxTuiO6n8BHgXmA9cEsZn+sEFhVNLwS2lyjzPXfPuvtzwEZCkqis4aSQSFZ8VSIiU8m4SSEa9K7X3fe5+0/dfWl0FtIXy1j2GmCZmS0xsxRwNSGpFPsu8IZoXbMI3UmVvwYi6j6KJVIVX5WIyFQyblKIrl6+cSILdvdc9NkHgA3A3e7+tJl93MyuiIo9AHSb2Xrgx4QRWLsnsr6jks+SI0FDUmceiYgUK2e4igfN7APAtwjjHgHg7nvH/shImfsIA+oVz7up6LUD74se1ZPPkLOETkcVERmlnKQwfD3CnxfNc2Dp8Q+nSvJZcpbUYHgiIqMcMSm4+5JqBFJV+UzoPtLVzCIihyjniuZ3lJrv7l89/uFUST5Ljri6j0RERimn++gVRa8bgYuBx4EpnBQyZEho3CMRkVHK6T76i+JpM5tGGPpi6ipkyar7SETkMBOpFQeoxgVmlZTPknGdfSQiMlo5xxT+k4PDU8SA5cDdlQyq4vIZMh7X2UciIqOUc0zhH4pe54AX3L2zQvFUR3RMQd1HIiKHKicpbAV2uPsQgJk1mdlid3++opFVUj5LuqCzj0RERitnV/nbQKFoOh/Nm7I86j7S2UciIocqp1ZMRDfJASB6PaVHkvOczj4SESmlnFqxq2gAO8zsSmBP5UKqPM9nlBREREoo55jCDcDXzey2aLoTKHmV81ThuQxZ2jVKqojIKOVcvPYs8CozawXM3cu5P/PkprOPRERKOmKtaGafNLMOd+9z9wNmNt3M/r4awVVMPkPWlRREREYrp1Zc5e49wxPuvg+4vHIhVcHIgHhKCiIixcqpFeNmNnKHezNrAqb2He9Hxj7SMQURkWLlHGj+N+BHZvblaPpa4M7KhVR5VsjqmIKISAnlHGj+tJk9CVwCGPBfwCmVDqySLB+1FDT2kYjIIcqtFXcSrmr+fcL9FDZULKJKKxSIeS460KzuIxGRYmO2FMzsdOBq4BqgG/gW4ZTUN1QptsooZAHI6iY7IiKHGa/76DfAz4A3u/tmADP7q6pEVUn5MGKHjimIiBxuvFrx9wndRj82s38xs4sJxxSmtnxoKegezSIihxszKbj7Pe5+FXAG8D/AXwFzzezzZnZpleI7/vIHu4+aNMyFiMghjth/4u797v51d38TsBB4AvhQxSOrlKLuo8aUuo9ERIodVa3o7nvd/Yvu/luVCqjioqSQtwSpuJKCiEix+qsVo+4ji6cwm/qHSEREjqc6TArR/YLiU/o+QSIiFVF/SSG6TiGeTNY4EBGRyaf+kkLUfRSPT+0x/UREKqEOk0LoPrKkkoKIyGh1mxTUfSQicrg6TApR91FCLQURkdHqMCmElkIy1VjjQEREJp86TArDZx+ppSAiMlrdJoVkSscURERGq8OkoO4jEZGx1F1ScCUFEZExVTQpmNllZrbRzDab2Zgjq5rZH5iZm9nKSsYDkM2kAUgpKYiIHKZiScHM4sDtwCpgOXCNmS0vUa4NeA/wSKViKZYbTgoNGvtIRGS0SrYUzgc2u/sWd88AdwFXlij3CeDTwFAFYxmRzYXuo8aGpmqsTkRkSqlkUlgAvFg03RnNG2Fm5wKL3P374y3IzK43s7Vmtrarq+uYgspHLYUGtRRERA5TyaRQ6mYFPvKmWQz4LPD+Iy3I3e9w95XuvnL27NnHFFQumybtCZpSiWNajojIiaiSSaETWFQ0vRDYXjTdBpwN/I+ZPQ+8Cri30geb89m07s8sIjKGSiaFNcAyM1tiZingauDe4Tfdfb+7z3L3xe6+GHgYuMLd11YwJgq5TEgKKSUFEZHRKpYU3D0H3Ag8AGwA7nb3p83s42Z2RaXWeySFbEYtBRGRMVS0Y93d7wPuGzXvpjHKvr6SsQwr5DNk1FIQESmp7o62FnIZCh5XS0FEpIS6SwqOwOaZAAAOLUlEQVSey5BXS0FEpKS6G/uIvI4piIiMpW6TQjJe6jIKEZH6VodJIUveEpgpKYiIjFZ/SaGQIx/TDXZEREqpu6QQK2QomJKCiEgpdZcULJ/FY3V30pWISFnqLinEPIur+0hEpKS6SwrxQhaPa9hsEZFS6i8peE4tBRGRMdRdUoh5DtRSEBEpqe6SQsKzEFdLQUSklLpLCo2k8YTuzywiUkp9JYXsEE2kyTVMq3UkIiKTUl0lhcLAPgByqY4aRyIiMjnVVVLI9O0FwBvVUhARKaXOkkI3AN40vcaRiIhMTnWWFEJLwZQURERKqqukkO8PSSHWrKQgIlJKnSWFcKA53jyjxpGIiExOdZUUfHAfBTeSLTrQLCJSSl0lBQb3sZ8WGlO6ollEpJS6Sgo21MN+b6E5Fa91KCIik1Jd3W0mlu6hhxY6kkoKIvUgm83S2dnJ0NBQrUOpmsbGRhYuXEgyObEekbpKCol0L/u9lflqKYjUhc7OTtra2li8eDFmVutwKs7d6e7uprOzkyVLlkxoGXXVfZTM9IRjCmopiNSFoaEhZs6cWRcJAcDMmDlz5jG1jOoqKaSy++nxVh1TEKkj9ZIQhh3r962fpFAo0JA7wAFrIRmvn68tInI06qd2zBwgRoGBWHutIxGROtHd3c2KFStYsWIF8+bNY8GCBSPTmUymrGVce+21bNy4scKRHlQ/B5oHe8JToq3GgYhIvZg5cyZPPPEEADfffDOtra184AMfOKSMu+PuxGKl99G//OUvVzzOYnWUFMIQF0MJtRRE6tHH/vNp1m/vPa7LXH5SOx9981lH/bnNmzfzlre8hQsvvJBHHnmE73//+3zsYx/j8ccfZ3BwkKuuuoqbbroJgAsvvJDbbruNs88+m1mzZnHDDTdw//3309zczPe+9z3mzJlzXL9T/XQfRUkhndQQFyJSe+vXr+e6667jV7/6FQsWLOBTn/oUa9euZd26dTz44IOsX7/+sM/s37+fiy66iHXr1vHqV7+a1atXH/e46qelMBS6j7JJtRRE6tFE9ugr6dRTT+UVr3jFyPQ3v/lNvvSlL5HL5di+fTvr169n+fLlh3ymqamJVatWAfDyl7+cn/3sZ8c9rvpJClFLIdegW3GKSO21tLSMvN60aROf+9znePTRR+no6ODtb397yWsNUqnUyOt4PE4ulzvucdVR91FoKRRS6j4Skcmlt7eXtrY22tvb2bFjBw888EDNYqmflsL5f8I7H55La2NzrSMRETnEeeedx/Llyzn77LNZunQpF1xwQc1iMXev2conYuXKlb527doJffaCT/03rz51Jv/w1pcd56hEZDLasGEDZ555Zq3DqLpS39vMHnP3lUf6bP10HwEDmZyGuBARGUdFk4KZXWZmG81ss5l9qMT77zOz9Wb2pJn9yMxOqWQ8g9k8TRoMT0RkTBVLCmYWB24HVgHLgWvMbPmoYr8CVrr7S4HvAJ+uVDyFgjOULWiEVBGRcVSypXA+sNndt7h7BrgLuLK4gLv/2N0HosmHgYWVCiadKwDQpO4jEZExVTIpLABeLJrujOaN5Trg/lJvmNn1ZrbWzNZ2dXVNKJiBTDifV8cURETGVsmkUGpQ75KnOpnZ24GVwP8p9b673+HuK9195ezZsycUzGA2D6DuIxGRcVTyOoVOYFHR9EJg++hCZnYJ8GHgIndPVyqYoSgp6ECziFRLd3c3F198MQA7d+4kHo8zvGP76KOPHnKF8nhWr17N5Zdfzrx58yoW67BKJoU1wDIzWwJsA64G3lZcwMzOBb4IXObuuysYC4OZ6JiCkoKIVEk5Q2eXY/Xq1Zx33nlTOym4e87MbgQeAOLAand/2sw+Dqx193sJ3UWtwLejW8htdfcrKhGPjimI1Ln7PwQ7nzq+y5x3Dqz61IQ+euedd3L77beTyWR4zWtew2233UahUODaa6/liSeewN25/vrrmTt3Lk888QRXXXUVTU1NR9XCmIiKDnPh7vcB942ad1PR60squf5iI8cUlBREpMZ+/etfc8899/DLX/6SRCLB9ddfz1133cWpp57Knj17eOqpkLx6enro6Ojgn//5n7nttttYsWJFxWOrm7GPdExBpM5NcI++En74wx+yZs0aVq4Mo04MDg6yaNEi3vjGN7Jx40be+973cvnll3PppZdWPba6SQrDLQV1H4lIrbk77373u/nEJz5x2HtPPvkk999/P7feeiv//u//zh133FHV2Opm7KOBjFoKIjI5XHLJJdx9993s2bMHCGcpbd26la6uLtydt771rSO35wRoa2vjwIEDVYmtfloKGR1TEJHJ4ZxzzuGjH/0ol1xyCYVCgWQyyRe+8AXi8TjXXXcd7o6ZccsttwBw7bXX8sd//MdVOdBcN0Nn/+Dpndzzq23ces25JON100ASqWsaOvugcofOrpuWwqVnzePSsyp/jq+IyFSmXWYRERmhpCAiJ7Sp1kV+rI71+yopiMgJq7Gxke7u7rpJDO5Od3c3jY2NE15G3RxTEJH6s3DhQjo7O5nokPtTUWNjIwsXTvzWNEoKInLCSiaTLFmypNZhTCnqPhIRkRFKCiIiMkJJQURERky5K5rNrAt4YQIfnQXsOc7hHA+K6+hM1rhg8samuI7OZI0Lji22U9z9iPcznnJJYaLMbG05l3hXm+I6OpM1Lpi8sSmuozNZ44LqxKbuIxERGaGkICIiI+opKVT3ThXlU1xHZ7LGBZM3NsV1dCZrXFCF2OrmmIKIiBxZPbUURETkCJQURERkxAmfFMzsMjPbaGabzexDNYxjkZn92Mw2mNnTZvbeaP7NZrbNzJ6IHpfXKL7nzeypKIa10bwZZvagmW2KnqdXOaaXFG2XJ8ys18z+shbbzMxWm9luM/t10byS28eCW6Pf3JNmdl4NYvs/ZvabaP33mFlHNH+xmQ0WbbsvVDmuMf92Zva30TbbaGZvrHJc3yqK6XkzeyKaX83tNVYdUd3fmbufsA8gDjwLLAVSwDpgeY1imQ+cF71uA54BlgM3Ax+YBNvqeWDWqHmfBj4Uvf4QcEuN/5Y7gVNqsc2A1wHnAb8+0vYBLgfuBwx4FfBIDWK7FEhEr28pim1xcbkaxFXybxf9L6wDGoAl0f9tvFpxjXr/H4GbarC9xqojqvo7O9FbCucDm919i7tngLuAK2sRiLvvcPfHo9cHgA3AglrEchSuBO6MXt8JvKWGsVwMPOvuE7ma/Zi5+0+BvaNmj7V9rgS+6sHDQIeZza9mbO7+A3fPRZMPAxMfS/k4xjWOK4G73D3t7s8Bmwn/v1WNy8wM+EPgm5VY93jGqSOq+js70ZPCAuDFoulOJkFFbGaLgXOBR6JZN0bNv9XV7qIp4sAPzOwxM7s+mjfX3XdA+MECc2oUG8DVHPqPOhm22VjbZ7L97t5N2KMctsTMfmVmPzGz19YgnlJ/u8myzV4L7HL3TUXzqr69RtURVf2dnehJwUrMq+k5uGbWCvw78Jfu3gt8HjgVWAHsIDRda+ECdz8PWAX8uZm9rkZxHMbMUsAVwLejWZNlm41l0vzuzOzDQA74ejRrB3Cyu58LvA/4hpm1VzGksf52k2WbXcOhOx9V314l6ogxi5aYd8zb7ERPCp3AoqLphcD2GsWCmSUJf+yvu/t/ALj7LnfPu3sB+Bcq1GQ+EnffHj3vBu6J4tg13ByNnnfXIjZConrc3XdFMU6KbcbY22dS/O7M7J3Am4A/8qgTOuqe6Y5eP0bouz+9WjGN87er+TYzswTwe8C3hudVe3uVqiOo8u/sRE8Ka4BlZrYk2tu8Gri3FoFEfZVfAja4+2eK5hf3Af4u8OvRn61CbC1m1jb8mnCQ8teEbfXOqNg7ge9VO7bIIXtvk2GbRcbaPvcC74jODnkVsH+4+V8tZnYZ8EHgCncfKJo/28zi0eulwDJgSxXjGutvdy9wtZk1mNmSKK5HqxVX5BLgN+7eOTyjmttrrDqCav/OqnFUvZYPwhH6ZwgZ/sM1jONCQtPuSeCJ6HE58DXgqWj+vcD8GsS2lHDmxzrg6eHtBMwEfgRsip5n1CC2ZqAbmFY0r+rbjJCUdgBZwh7adWNtH0Kz/vboN/cUsLIGsW0m9DcP/9a+EJX9/ehvvA54HHhzleMa828HfDjaZhuBVdWMK5r/FeCGUWWrub3GqiOq+jvTMBciIjLiRO8+EhGRo6CkICIiI5QURERkhJKCiIiMUFIQEZERSgoiETPL26Gjsh63UXWj0TZrdT2FSNkStQ5AZBIZdPcVtQ5CpJbUUhA5gmh8/VvM7NHocVo0/xQz+1E0uNuPzOzkaP5cC/cwWBc9XhMtKm5m/xKNlf8DM2uKyr/HzNZHy7mrRl9TBFBSECnWNKr76Kqi93rd/XzgNuCfonm3EYYufilhwLlbo/m3Aj9x95cRxu1/Opq/DLjd3c8CeghXy0IYI//caDk3VOrLiZRDVzSLRMysz91bS8x/Hvgtd98SDVi2091nmtkewjAN2Wj+DnefZWZdwEJ3TxctYzHwoLsvi6Y/CCTd/e/N7L+APuC7wHfdva/CX1VkTGopiJTHx3g9VplS0kWv8xw8pvc7hDFsXg48Fo3WKVITSgoi5bmq6Pmh6PUvCSPvAvwR8PPo9Y+APwUws/h44++bWQxY5O4/Bv4G6AAOa62IVIv2SEQOarLohu2R/3L34dNSG8zsEcKO1DXRvPcAq83sr4Eu4Npo/nuBO8zsOkKL4E8Jo3KWEgf+zcymEUa9/Ky79xy3byRylHRMQeQIomMKK919T61jEak0dR+JiMgItRRERGSEWgoiIjJCSUFEREYoKYiIyAglBRERGaGkICIiI/4/2XnOO7iYATgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc_treino, label='Train')\n",
    "plt.plot(epochs, acc_teste, label='Test')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.title(\"CNN 00 Mnist Classifier\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

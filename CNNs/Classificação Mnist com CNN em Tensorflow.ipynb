{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0413 00:55:02.396085 140633614988672 deprecation.py:323] From <ipython-input-1-2f7a547f03eb>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0413 00:55:02.400234 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0413 00:55:02.422096 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0413 00:55:12.129390 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0413 00:55:12.919698 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0413 00:55:12.931915 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0413 00:55:15.772166 140633614988672 deprecation.py:323] From /home/george/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parâmetros gerais\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametros da rede neural\n",
    "n_entrada = 784\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variáveis preditoras e target (em forma de placeholders)\n",
    "x = tf.placeholder(tf.float32, [None, n_entrada])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#criando funções com os procedimentos da CNN (convolução e maxpooling)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(entrada, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(entrada, w, strides=[1,1,1,1], padding = \"VALID\"), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(entrada, k):\n",
    "    return tf.nn.max_pool(entrada, ksize = [1,k,k,1], strides = [1,k,k,1], padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normalizando a entrada para a convolução conseguir ser executada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_redimensionado = tf.reshape(x, shape = [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Iniciando os pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=tf.Variable(tf.random_normal([5,5,1,32], stddev=0.05))\n",
    "w2=tf.Variable(tf.random_normal([5,5,32,64], stddev=0.05))\n",
    "w_denso_1 = tf.Variable(tf.random_normal([4*4*64,80], stddev=0.0063))\n",
    "w_out = tf.Variable(tf.random_normal([80, n_classes], stddev=0.04))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([32]))\n",
    "b2 = tf.Variable(tf.zeros([64]))\n",
    "b_denso_1 = tf.Variable(tf.zeros([80]))\n",
    "b_out = tf.Variable(tf.zeros([n_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#definindo a estrutura da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camada 1\n",
    "conv1 = conv2d(x_redimensionado,w1,b1)\n",
    "pool1 = max_pool(conv1, k=2)\n",
    "#drop1 = tf.nn.dropout(pool1, rate=0.2)\n",
    "\n",
    "#camada 2\n",
    "conv2 = conv2d(pool1,w2,b2)\n",
    "pool2 = max_pool(conv2, k=2)\n",
    "#drop2 = tf.nn.dropout(pool2, rate=0.2)\n",
    "\n",
    "#camada densa oculta\n",
    "drop2_redimensionada = tf.reshape(pool2, shape=[-1, w_denso_1.get_shape().as_list()[0]]) #flatten\n",
    "densa = tf.nn.relu(tf.add(tf.matmul(drop2_redimensionada, w_denso_1), b_denso_1))\n",
    "drop_densa = tf.nn.dropout(densa, rate=0.2)\n",
    "\n",
    "#camada de saída\n",
    "out = tf.add(tf.matmul(drop_densa, w_out), b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#otimizador e função de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "custo = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out, labels=y))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(custo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos = tf.equal(tf.argmax(out,1), tf.argmax(y,1))#checa quantos elementos são iguais\n",
    "acuracia = tf.reduce_mean(tf.cast(acertos, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#inicializando as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', '1,', 'Custo medio de treino = ', '0.368')\n",
      "('Acc test = ', '0.966')\n",
      "('Epoch: ', '2,', 'Custo medio de treino = ', '0.094')\n",
      "('Acc test = ', '0.980')\n",
      "('Epoch: ', '3,', 'Custo medio de treino = ', '0.066')\n",
      "('Acc test = ', '0.983')\n",
      "('Epoch: ', '4,', 'Custo medio de treino = ', '0.050')\n",
      "('Acc test = ', '0.986')\n",
      "('Epoch: ', '5,', 'Custo medio de treino = ', '0.040')\n",
      "('Acc test = ', '0.989')\n",
      "('Epoch: ', '6,', 'Custo medio de treino = ', '0.035')\n",
      "('Acc test = ', '0.988')\n",
      "('Epoch: ', '7,', 'Custo medio de treino = ', '0.029')\n",
      "('Acc test = ', '0.989')\n",
      "('Epoch: ', '8,', 'Custo medio de treino = ', '0.025')\n",
      "('Acc test = ', '0.987')\n",
      "('Epoch: ', '9,', 'Custo medio de treino = ', '0.022')\n",
      "('Acc test = ', '0.988')\n",
      "('Epoch: ', '10,', 'Custo medio de treino = ', '0.020')\n",
      "('Acc test = ', '0.990')\n",
      "Treinamento concluído!\n",
      "('Acc do Modelo:', 0.9902)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#abrindo a sessão\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #cliclo de treinamento - epochs\n",
    "    for epoch in range(epochs):\n",
    "        custo_medio = 0.0\n",
    "        total_batches = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        #loop para os batchs\n",
    "        for i in range(total_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            #fit training usando batch data\n",
    "            sess.run(otimizador, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            #computando o custo médio de uma epoch completa: Soma tudo e divide pela quantidade de batchs\n",
    "            custo_medio += sess.run(custo, feed_dict={x: batch_x, y: batch_y}) / total_batches\n",
    "            \n",
    "        #calculando a acurácia em cada época\n",
    "        acuracia_teste = sess.run(acuracia, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        \n",
    "        #mostrando resultados após cada época\n",
    "        print(\"Epoch: \", \"{},\".format((epoch + 1)), \"Custo medio de treino = \", \"{:.3f}\". format(custo_medio))\n",
    "        print(\"Acc test = \", \"{:.3f}\".format(acuracia_teste))\n",
    "        \n",
    "    print (\"Treinamento concluído!\")\n",
    "    print(\"Acc do Modelo:\", acuracia.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
